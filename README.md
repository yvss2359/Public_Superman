# âš¡ Superman â€“ Inference API for Energy Forecasting

This project exposes a FastAPI endpoint that loads models from MLflow, processes energy consumption features, applies a scaler, and predicts values using an XGBoost model. It supports inference over a time period (`T1`, `T2`), and pushes results to Kafka for monitoring (e.g., via NannyML).

---

## ðŸ› ï¸ Tech Stack

- [FastAPI](https://fastapi.tiangolo.com/)
- [MLflow](https://mlflow.org/)
- [Kafka](https://kafka.apache.org/)
- Docker (for deployment)

---

## ðŸš€ Usage

### 1. Create & configure `.env`

```env
MLFLOW_TRACKING_URI=....
MODEL_NAME=EnergyForecastModel_xgboost
SCALER_NAME=Scaler_standard
MODEL_STAGE=prod
AWS_ACCESS_KEY_ID=mlflow
AWS_SECRET_ACCESS_KEY=****
MLFLOW_S3_ENDPOINT_URL=....
KAFKA_BOOTSTRAP_SERVERS=....
KAFKA_TOPIC=energy_forecast
```

### 2. Install requirements

```bash
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 3. Run the API

```bash
uvicorn app.main:app --reload
```

Access documentation at [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ðŸ§ª Testing

```bash
pytest tests/
```

---

## ðŸ“¤ Example Request

POST `/predict`

```json
{
  "T1": "2025-06-01",
  "T2": "2025-06-05"
}
```

Response:

```json
{
  "prediction": [1234.5, 1200.2, ...]
}
```

---

## ðŸ”Œ Kafka Integration

Predictions are sent to the Kafka topic `inference_topic`. You can listen to this topic to track predictions in real time.

---

## ðŸ“¦ Docker

```bash
docker build -t superman-inference .
docker run --env-file .env -p 8000:8000 superman-inference
```

Or use Docker Compose:

```bash
docker-compose up --build
```

---

## ðŸ“ Project Structure

```
Superman/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # FastAPI app
â”‚   â”œâ”€â”€ model.py            # MLflow model loading
â”‚   â”œâ”€â”€ schemas.py          # Pydantic input/output models
â”‚   â””â”€â”€ utils.py            # Preprocessing, scaling, Kafka
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data_preprocessing.py  # Raw data handling & transformation
â”‚   â””â”€â”€ features_engineering.py # Feature generation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

![Project Structure](./structure.png "Project Structure")
---

## ðŸ“Ž Notes

* Make sure the models (`Scaler_standard` and `EnergyForecastModel_xgboost`) are correctly logged under the alias `prod`.
* The inference will fail if you provide a date range that is too large (e.g. > 7 days).
* The tempo dataset URL is dynamically generated using the year of `T2`.
* The API will download and process the relevant data automatically based on your input.
